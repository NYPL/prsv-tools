#/usr/bin/python3

#   Preservica Opex Export Unpacker (multi bitstream) Script
#
#   andy.dean@preservica.com
#
#   Developed By:
#   Preservica ltd
#   22 The Quadrant
#   Abingdon Science Park
#   Abingdon
#   OX14 3YS
#
#   email:  info@preservica.com
#   web:    www.preservica.com
#
#   THIS SCRIPTS IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT
#   LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.
#
#   Use at your own risk. Test it in your environment, and ensure that the resulting multi-line report is representative 
#   of the types of asset metadata (xip) that you have exported from Preservica.
#
#   Generate a "metadata only" export. Acquire the <export.zip> and place it into the Export_Source folder
#   Run "\Scripts\v6_opex_unpack_multi_BS_<date>.py"
#   View the report in \Export_Target



# import
import time
import sys
from datetime import datetime
from pathlib import Path
import os
import shutil
from shutil import unpack_archive
from pathlib import Path
import lxml.etree
import logging
import lxml.etree
from xlsxwriter import Workbook
import pandas as pd
# from multiprocessing import Pool


#csvtoxlsx
import csv
#from xlsxwriter.workbook import Workbook


#  working folders
parent_folder = Path("/containers/metadata_exports/")
root_folder = Path("/containers/")
source_folder = root_folder / "Export_Source"
working_folder = root_folder / "Export_Working"
target_folder = root_folder / "Export_Target"
log_folder = root_folder / "Export_Log"
Page_Folder = "Individual Pages"


###############################################################
#  user switches
###############################################################
#  set to 1 to disable querying XIP metadata for key values
disable_metadata_query = 0


###############################################################
#  standard functions
###############################################################
def fTime():
    query_time_Time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    return query_time_Time


def fIntTime():
    query_time_IntTime = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
    return query_time_IntTime


def fEffectiveDateTime():
    query_time_EffectiveDateTime = datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ")
    return query_time_EffectiveDateTime


###############################################################
#  logging
###############################################################
    #LogFile = log_folder / f"PAX_Unpacker_LogFile_{str(fTime())}.log"

    # logging.basicConfig(level=logging.DEBUG, filename=LogFile, filemode='w', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    # logging.basicConfig(handlers=[logging.FileHandler(LogFile, 'w', 'utf-8')], level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logging.basicConfig(level=logging.DEBUG)
    # logging.info(" ----------------------- generated by " + str(__file__) + " -----------------------")


###############################################################
#  list objects
###############################################################


list_unpacked_export_zips = []

list_XIP_IORef = []
list_XIP_IOTitle = []
list_XIP_IOParent = []
listCO = []
list_XIP_Entity = []
list_XIP_WorkingPath = []

list_XIP_BSFileName = []
list_XIP_BSFileSize = []
list_XIP_BSAlg = []
list_XIP_BSFV = []

#  dictionary objects
dict_XIP_IORef = {}
dict_XIP_IOTitle = {}
dict_XIP_IOParent = {}
dict_XIP_CORef = {}
dict_XIP_COTitle = {}
dict_XIP_COParent = {}
dict_XIP_GenRef = {}
dict_XIP_GenBitstream = {}
dict_XIP_GenFormats = {}
dict_XIP_Identifier = {}

dict_BSFileName = {}
dict_BSFileSize = {}
dict_BSFileName_MD5 = {}
dict_BSFileName_SHA1 = {}
dict_BSFileName_SHA256 = {}
dict_BSFileName_SHA512 = {}
dict_BSRepresentationType = {}
dict_BSGeneration = {}

dictCO = {}

dict_XIP_Entity = {}
dict_XIP_WorkingPath = {}

dict_NS = {}

###############################################################
#  custom functions
###############################################################
def fProcessPackages(source_folder: Path ,working_folder: Path, target_folder: Path):
    global outputfile
    
    #process one export .zip at a time
    for packages in parent_folder.iterdir():
        # skip hidden files
        if str(packages.name).startswith("."):
            continue
        # sanitise working_folder
        fCleanUp(working_folder)
        
        dictCO.clear()

        for pkg in packages.iterdir():
            # accounts for top-level folder being unzipped
            source_dir = Path(source_folder / packages / pkg)
            #check if file exists 
            #define output 
            outputfile_name = f"{pkg.stem}_Info.csv"
            xlsx_outputfile_name = f"{pkg.stem}_Info.xlsx"
            if Path(target_folder / pkg.stem[:3]).is_dir():
                outputfile_path = Path(target_folder/ pkg.stem[:3]/ outputfile_name)
                xlsx_outputfile_path = Path(target_folder, pkg.stem[:3], xlsx_outputfile_name)
            else: 
                Path(target_folder / pkg.stem[:3]).mkdir()
                outputfile_path = Path(target_folder/ pkg.stem[:3]/ outputfile_name)
                xlsx_outputfile_path = Path(target_folder, pkg.stem[:3], xlsx_outputfile_name)

            if xlsx_outputfile_path.is_file():
                continue
            else:

                # skip hidden files
                if str(pkg.name).startswith("."):
                    continue
                if source_dir.is_dir():
                    # print("fProcessPackages : source directory contains folders but should only contain zips")
                    logging.info(" : fProcessPackages : source directory contains folders")
                    sys.exit()
                else:
                    if pkg.is_file():
                        # package_ext = pkg.suffix()
                        # package_no_ext = pkg.stem()
                        if pkg.suffix == ".zip":
                            logging.info(f" : fProcessPackages : Processing : {pkg}")

                            outputfile = open(outputfile_path, "w", encoding = 'utf-8')                    
                            # outputfile.write("Local_Path|IO Ref|IO Title|Identifier|Parent Ref|CO Ref|CO Title|CO Parent|Representation Type|Generation|File Path|File Name|File Size|SHA512|SHA512ChecksumVal|SHA256|SHA256ChecksumVal|SHA1|SHA1ChecksumVal|MD5|MD5ChecksumVal|Formats|IngestDate|IngestUser|IngestWFName|IngestWFInstanceID" + "\n", )
                            output_headers = ["Local_Path", "IO Ref", "IO Title", "Identifier", "Parent Ref", "CO Ref", "CO Title", "CO Parent", "Representation Type", "Generation", "File Path", "File Name", "File Size", "SHA512", "SHA512ChecksumVal", "SHA256", "SHA256ChecksumVal", "SHA1", "SHA1ChecksumVal", "MD5", "MD5ChecksumVal", "Formats", "IngestDate", "IngestUser", "IngestWFName", "IngestWFInstanceID"]
                            csv_writer = csv.writer(outputfile)
                            csv_writer.writerow(output_headers)

                            package_source = Path(source_folder, packages, pkg)
                            package_working = Path(working_folder)
                            shutil.copy2(package_source,package_working)

                            fUnzipExport(working_folder)

                            fQueryXIP(working_folder)
                            fDumpdict(pkg.stem)
                            outputfile.close()

                            # fConvertCSVtoXLSX(outputfile_path, xlsx_outputfile_path)
                            # if xlsx_outputfile_path.is_file():
                            #     outputfile_path.touch()
                            #     outputfile_path.unlink()
                            # else:
                            #     logging.error(f"{xlsx_outputfile_name} does not exist, CSV will not be deleted.")
                        else:
                            logging.info(f" : fProcessPackages : Non zipped files will not be processed : {pkg}")


def fUnzipExport(working_folder):
    zip_files = Path(working_folder).rglob("*.zip")
    while True:
        try:
            path = next(zip_files)
        except StopIteration:
            break # no more files
        except PermissionError:
            logging.exception("permission error")
        else:
            # print("     Unzipping : " + str(path))
            extract_dir = path.with_name(path.stem)
            unpack_archive(path, extract_dir, 'zip')
            list_unpacked_export_zips.append(path)
    
    for zipper in list_unpacked_export_zips:
        fDeleteZip(zipper)


def fQueryXIP(working_folder):
    for path in Path(working_folder).rglob('*.xip'):
        fParseXIP(path)


def fDumpdict(pkg_id):
    array_dictCO = list(dictCO.keys())
    for aa in range(len(array_dictCO)):
        # print(f"CO array {array_dictCO[aa]}")
        # outputfile.write(f"{dictCO[array_dictCO[aa]]} \n")
        str_output = str(dictCO[array_dictCO[aa]])
        split_output = str_output.split(sep="|")
        for item in split_output:
            if pkg_id in item[2]:
                csv_writer = csv.writer(outputfile)
                csv_writer.writerow(split_output)


def fDeleteZip(zipper: Path):
    if zipper.is_file():
        try:
            zipper.unlink()
            # print(f"     Deleting zip : {zipper}")
            # logging.info(f" : fDeleteZip : zip deleted {zipper}")
        except OSError as oser1:
            logging.info(f" : fDeleteZip : delete failed for {zipper}{oser1}")
    else:
        logging.info(f" : fDeleteZip : delete failed because the zip file does not exist {zipper}")
       
       
def fParseXIP(path):
    #  modify this section as necessary
    # print(f"path {path}")
    # logging.info(f"fParseXIP : {path}")
    xml = open(path, "r",  encoding = 'utf-8')
    xml_string = xml.read()
    
    xml = bytes(bytearray(xml_string, encoding='utf-8'))
    tree = lxml.etree.fromstring(xml)
    root = lxml.etree.Element("tree")
    
    fReset_Lists_Dicts()
    
    XIP_IORef = ""
    XIP_IOTitle = ""
    XIP_CORef = ""
    XIP_IOParent = ""
    
    ADDate_val = ""
    ADUser_val = ""
    ADWfName_val = ""
    ADWfInstID_val = ""
    
    
    #  process nsmap and determine Preservica version
    dict_NS.clear()
    for ns_key, ns_value in tree.nsmap.items():
        # print(ns_key)
        # print(ns_value)
        if (ns_key is None) and ("preservica.com/xip" in ns_value.lower()):
            ns_new_key = "XIP"
            ns_new_value = ns_value
            dict_NS[ns_new_key] = ns_new_value
        else:
            ns_new_key = ns_key.upper()
            ns_new_value = ns_value
            dict_NS[ns_new_key] = ns_new_value
    NSMAP = dict_NS
    # print(NSMAP)
    

    IO_data = tree.xpath('//XIP:XIP/XIP:InformationObject', namespaces = NSMAP)
    for IO in range (len(IO_data)):
        IOentry = IO_data[IO]
        IORef_val = IOentry.xpath('./XIP:Ref/text()', namespaces = NSMAP)
        for IORef in IORef_val:
            XIP_IORef = IORef
        IOTitle_val = IOentry.xpath('./XIP:Title/text()', namespaces=NSMAP)
        for IOTitle in IOTitle_val:
            XIP_IOTitle = IOTitle
        IOParent_val = IOentry.xpath('./XIP:Parent/text()', namespaces=NSMAP)
        for IOParent in IOParent_val:
            XIP_IOParent = IOParent


    # retrieves audit history data
    Audit_data = tree.xpath('//XIP:XIP/XIP:EventAction[@commandType="command_create"]/XIP:Event[@type="Ingest"]', namespaces = NSMAP)
    for AD in range (len(Audit_data)):
        ADentry = Audit_data[AD]
        ADDate_val = ADentry.xpath('./XIP:Date/text()', namespaces = NSMAP)[0]
        ADUser_val = ADentry.xpath('./XIP:User/text()', namespaces = NSMAP)[0]
        ADWfName_val = ADentry.xpath('./XIP:WorkflowName/text()', namespaces = NSMAP)[0]
        ADWfInstID_val = ADentry.xpath('./XIP:WorkflowInstanceId/text()', namespaces = NSMAP)[0]
            


    Ident_data = tree.xpath('//XIP:XIP/XIP:Identifier', namespaces = NSMAP)
    for Ident in range(len(Ident_data)):
        Ident_entry = Ident_data[Ident]
        Id_Type = Ident_entry.xpath('./XIP:Type/text()', namespaces=NSMAP)
        Id_Value = Ident_entry.xpath('./XIP:Value/text()', namespaces=NSMAP)
        Id_Entity = Ident_entry.xpath('./XIP:Entity/text()', namespaces=NSMAP)
        if Id_Type.lower() == "seedurl":
            dict_XIP_Identifier[Id_Entity] = Id_Value
        else:
            dict_XIP_Identifier[Id_Entity] = ""
            

    CO_data = tree.xpath('//XIP:XIP/XIP:ContentObject', namespaces = NSMAP)
    for CO in range (len(CO_data)):
        COentry = CO_data[CO]
        CORef_val = COentry.xpath('./XIP:Ref/text()', namespaces = NSMAP)
        
        for CORef in CORef_val:
            dict_XIP_CORef[CORef] = CORef
            # logging.info(f"fParseXIP : CORef {CORef}")
        COTitle_val = COentry.xpath('./XIP:Title/text()', namespaces=NSMAP)
        for COTitle in COTitle_val:
            dict_XIP_COTitle[CORef] = COTitle
        COParent_val = COentry.xpath('./XIP:Parent/text()', namespaces=NSMAP)
        for COParent in COParent_val:
            dict_XIP_COParent[CORef] = COParent


    Gen_data = tree.xpath('//XIP:XIP/XIP:Generation', namespaces = NSMAP)
    list_GenFormats = []
    for Gen in range (len(Gen_data)):
        list_GenFormats.clear()
        Genentry = Gen_data[Gen]
        
        GenCORef_val = Genentry.xpath('./XIP:ContentObject/text()', namespaces = NSMAP)[0]
        # for CORef in GenRef_val:
        dict_XIP_GenRef[GenCORef_val] = GenCORef_val
        
        GenBitStream_val = Genentry.xpath('./XIP:Bitstreams/XIP:Bitstream/text()', namespaces=NSMAP)
        for GenBitStream in GenBitStream_val:
            # dict_XIP_GenBitstream[CORef] = GenBitStream
            dict_XIP_GenBitstream[GenBitStream] = GenCORef_val
        
        GenFormats_val = Genentry.xpath('./XIP:Formats/XIP:Format/XIP:PUID/text()', namespaces=NSMAP)
        for GenFormats in range(len(GenFormats_val)):
            list_GenFormats.append(GenFormats_val[GenFormats])
        dict_XIP_GenFormats[GenBitStream] = "^".join(list_GenFormats)
        

    Bitstream_data = tree.xpath('//XIP:XIP/XIP:Bitstream', namespaces = NSMAP)
    # print(f"Bitstream_data {Bitstream_data}")
    # print(len(Bitstream_data))
    for BS in range (len(Bitstream_data)):
        BSentry = Bitstream_data[BS]
        BSFileName_val = BSentry.xpath('./XIP:Filename/text()', namespaces = NSMAP)[0]
        # print(type(BSFileName_val))
        # print(len(BSFileName_val))
        BSFileSize_val = BSentry.xpath('./XIP:FileSize/text()', namespaces = NSMAP)[0]
        BSPhysicalLocation_val = BSentry.xpath('./XIP:PhysicalLocation/text()', namespaces = NSMAP)[0]
        # print(type(BSPhysicalLocation_val))
        # print(len(BSPhysicalLocation_val))

        BSBitstream = ""
        BSBitstream = f"{BSPhysicalLocation_val}/{BSFileName_val}"
        # logging.info(f"BSBitstream : {BSBitstream}")
        # print(f"BSBitstream {BSBitstream}")
        
        BSRepresentation_Type = BSBitstream.split(os.sep)[0].split("_")[1]
        dict_BSRepresentationType[BSBitstream] = BSRepresentation_Type
        
        BSGeneration = BSPhysicalLocation_val.split(os.sep)[-1].split("_")[-1]
        dict_BSGeneration[BSBitstream] = BSGeneration
        
        dict_BSFileName[BSBitstream] = BSFileName_val
        dict_BSFileSize[BSBitstream] = BSFileSize_val
        
        Fixity_data = BSentry.xpath('./XIP:Fixities/XIP:Fixity', namespaces = NSMAP)
        # logging.info(f"Fixity_data {Fixity_data}")
        # print(type(Fixity_data))
        fd_loop = 0
        for FD in range (len(Fixity_data)):
            # logging.info(f"FD_loop : {fd_loop}")
            BS_Fixity_alg_val = ""
            BS_Fixity_val = ""
            
            FDentry = Fixity_data[FD]
            
            BS_Fixity_alg_val  = FDentry.xpath('./XIP:FixityAlgorithmRef/text()', namespaces = NSMAP)[0]
            # logging.info(f"BSBitstream : {BSBitstream}")
            # logging.info(f"BS_Fixity_alg_val {BS_Fixity_alg_val}")
            # logging.info(f"BS_Fixity_alg_val type {type(BS_Fixity_alg_val)}")
            # logging.info(f"BS_Fixity_alg_val len{len(BS_Fixity_alg_val)}")
            # print(len(BS_Fixity_alg_val))
            
            
            BS_Fixity_val  = FDentry.xpath('./XIP:FixityValue/text()', namespaces = NSMAP)[0]
            # logging.info(f"BSBitstream : {BSBitstream}")
            # logging.info(f"BS_Fixity_val {BS_Fixity_val}")
            # logging.info(f"BS_Fixity_val {type(BS_Fixity_val)}")
            # logging.info(f"BS_Fixity_val {len(BS_Fixity_val)}")
            
            
            if BS_Fixity_alg_val == 'MD5':
                dict_BSFileName_MD5[BSBitstream] = BS_Fixity_val
            elif BS_Fixity_alg_val == 'SHA1':
                dict_BSFileName_SHA1[BSBitstream] = BS_Fixity_val
            elif BS_Fixity_alg_val == 'SHA256':
                dict_BSFileName_SHA256[BSBitstream] = BS_Fixity_val
            elif BS_Fixity_alg_val == 'SHA512':
                dict_BSFileName_SHA512[BSBitstream] = BS_Fixity_val
            
            fd_loop +=1

    Metadata = tree.xpath('//XIP:XIP/XIP:Metadata', namespaces = NSMAP)
    for md in range (len(Metadata)):
        mdentry = Metadata[md]
        Entity_val = mdentry.xpath('./XIP:Entity/text()', namespaces = NSMAP)
        for MDEntity in Entity_val:
            # print(f"MDEntity_val {MDEntity}")
            list_XIP_Entity.append(MDEntity)

    short_path = Path(path).parents[1]
    
    for dict_BSFileName_key, dict_BSFileName_val in dict_BSFileName.items():
        # print(f"dict_BSFileName_key {dict_BSFileName_key}")
        CORef_from_dict = dict_XIP_GenBitstream.get(dict_BSFileName_key, "NA")
        GenFormats_from_dict = dict_XIP_GenFormats.get(dict_BSFileName_key, "NA")
        #         path             IORef      IO Title     IO Identifier                             IO Parent     CO Ref           CO Title                                     CO Parent                                     Representation Type                                       Generation                                        Full file path            File Name                                       File Size                                                                                                                                                                                                                                                                                                                       Audit
        listCO = [str(short_path), XIP_IORef, XIP_IOTitle, dict_XIP_Identifier.get(XIP_IORef, "NA"), XIP_IOParent, CORef_from_dict, dict_XIP_COTitle.get(CORef_from_dict, "NA"), dict_XIP_COParent.get(CORef_from_dict, "NA"), dict_BSRepresentationType.get(dict_BSFileName_key, "NA"), dict_BSGeneration.get(dict_BSFileName_key, "NA"), str(dict_BSFileName_key), dict_BSFileName.get(dict_BSFileName_key, "NA"), dict_BSFileSize.get(dict_BSFileName_key, "NA"), "SHA512", dict_BSFileName_SHA512.get(dict_BSFileName_key, "NA"), "SHA256", dict_BSFileName_SHA256.get(dict_BSFileName_key, "NA"), "SHA1", dict_BSFileName_SHA1.get(dict_BSFileName_key, "NA"), "MD5", dict_BSFileName_MD5.get(dict_BSFileName_key, "NA"), GenFormats_from_dict, ADDate_val, ADUser_val, ADWfName_val, ADWfInstID_val]
        dictCO[dict_BSFileName_key] = "|".join(listCO)
       
       
       
       

def fParseXIP_old(path):
    #  modify this section as necessary
    # print(f"path {path}")
    # logging.info(f"fParseXIP : {path}")
    xml = open(path, "r",  encoding = 'utf-8')
    xml_string = xml.read()
    
    xml = bytes(bytearray(xml_string, encoding='utf-8'))
    tree = lxml.etree.fromstring(xml)
    root = lxml.etree.Element("tree")
    
    fReset_Lists_Dicts()
    
    XIP_IORef = ""
    XIP_IOTitle = ""
    XIP_CORef = ""
    XIP_IOParent = ""
    
    #  process nsmap and determine Preservica version
    dict_NS.clear()
    for ns_key, ns_value in tree.nsmap.items():
        # print(ns_key)
        # print(ns_value)
        if (ns_key is None) and ("preservica.com/xip" in ns_value.lower()):
            ns_new_key = "XIP"
            ns_new_value = ns_value
            dict_NS[ns_new_key] = ns_new_value
        else:
            ns_new_key = ns_key.upper()
            ns_new_value = ns_value
            dict_NS[ns_new_key] = ns_new_value
    NSMAP = dict_NS
    # print(NSMAP)
    

    IO_data = tree.xpath('//XIP:XIP/XIP:InformationObject', namespaces = NSMAP)
    for IO in range (len(IO_data)):
        IOentry = IO_data[IO]
        IORef_val = IOentry.xpath('./XIP:Ref/text()', namespaces = NSMAP)
        for IORef in IORef_val:
            XIP_IORef = IORef
        IOTitle_val = IOentry.xpath('./XIP:Title/text()', namespaces=NSMAP)
        for IOTitle in IOTitle_val:
            XIP_IOTitle = IOTitle
        IOParent_val = IOentry.xpath('./XIP:Parent/text()', namespaces=NSMAP)
        for IOParent in IOParent_val:
            XIP_IOParent = IOParent


    CO_data = tree.xpath('//XIP:XIP/XIP:ContentObject', namespaces = NSMAP)
    for CO in range (len(CO_data)):
        COentry = CO_data[CO]
        CORef_val = COentry.xpath('./XIP:Ref/text()', namespaces = NSMAP)
        
        for CORef in CORef_val:
            dict_XIP_CORef[CORef] = CORef
            # logging.info(f"fParseXIP : CORef {CORef}")
        COTitle_val = COentry.xpath('./XIP:Title/text()', namespaces=NSMAP)
        for COTitle in COTitle_val:
            dict_XIP_COTitle[CORef] = COTitle
        COParent_val = COentry.xpath('./XIP:Parent/text()', namespaces=NSMAP)
        for COParent in COParent_val:
            dict_XIP_COParent[CORef] = COParent


    Gen_data = tree.xpath('//XIP:XIP/XIP:Generation', namespaces = NSMAP)
    for Gen in range (len(Gen_data)):
        Genentry = Gen_data[Gen]
        GenRef_val = Genentry.xpath('./XIP:ContentObject/text()', namespaces = NSMAP)
        for CORef in GenRef_val:
            dict_XIP_GenRef[CORef] = CORef
        GenBitStream_val = Genentry.xpath('./XIP:Bitstreams/XIP:Bitstream/text()', namespaces=NSMAP)
        # print(f"GenBitStream_val {GenBitStream_val}")
        for GenBitStream in GenBitStream_val:
            # dict_XIP_GenBitstream[CORef] = GenBitStream
            dict_XIP_GenBitstream[GenBitStream] = CORef


    Bitstream_data = tree.xpath('//XIP:XIP/XIP:Bitstream', namespaces = NSMAP)
    # print(f"Bitstream_data {Bitstream_data}")
    # print(len(Bitstream_data))
    for BS in range (len(Bitstream_data)):
        BSentry = Bitstream_data[BS]
        BSFileName_val = BSentry.xpath('./XIP:Filename/text()', namespaces = NSMAP)[0]
        # print(type(BSFileName_val))
        # print(len(BSFileName_val))
        BSFileSize_val = BSentry.xpath('./XIP:FileSize/text()', namespaces = NSMAP)[0]
        BSPhysicalLocation_val = BSentry.xpath('./XIP:PhysicalLocation/text()', namespaces = NSMAP)[0]
        # print(type(BSPhysicalLocation_val))
        # print(len(BSPhysicalLocation_val))

        BSBitstream = ""
        BSBitstream = f"{BSPhysicalLocation_val}/{BSFileName_val}"
        # logging.info(f"BSBitstream : {BSBitstream}")
        # print(f"BSBitstream {BSBitstream}")
        
        dict_BSFileName[BSBitstream] = BSFileName_val
        dict_BSFileSize[BSBitstream] = BSFileSize_val
        
        Fixity_data = BSentry.xpath('./XIP:Fixities/XIP:Fixity', namespaces = NSMAP)
        # logging.info(f"Fixity_data {Fixity_data}")
        # print(type(Fixity_data))
        fd_loop = 0
        for FD in range (len(Fixity_data)):
            # logging.info(f"FD_loop : {fd_loop}")
            BS_Fixity_alg_val = ""
            BS_Fixity_val = ""
            
            FDentry = Fixity_data[FD]
            
            BS_Fixity_alg_val  = FDentry.xpath('./XIP:FixityAlgorithmRef/text()', namespaces = NSMAP)[0]
            # logging.info(f"BSBitstream : {BSBitstream}")
            # logging.info(f"BS_Fixity_alg_val {BS_Fixity_alg_val}")
            # logging.info(f"BS_Fixity_alg_val type {type(BS_Fixity_alg_val)}")
            # logging.info(f"BS_Fixity_alg_val len{len(BS_Fixity_alg_val)}")
            # print(len(BS_Fixity_alg_val))
            
            
            BS_Fixity_val  = FDentry.xpath('./XIP:FixityValue/text()', namespaces = NSMAP)[0]
            # logging.info(f"BSBitstream : {BSBitstream}")
            # logging.info(f"BS_Fixity_val {BS_Fixity_val}")
            # logging.info(f"BS_Fixity_val {type(BS_Fixity_val)}")
            # logging.info(f"BS_Fixity_val {len(BS_Fixity_val)}")
            
            
            if BS_Fixity_alg_val == 'MD5':
                dict_BSFileName_MD5[BSBitstream] = BS_Fixity_val
            elif BS_Fixity_alg_val == 'SHA1':
                dict_BSFileName_SHA1[BSBitstream] = BS_Fixity_val

            fd_loop +=1

    Metadata = tree.xpath('//XIP:XIP/XIP:Metadata', namespaces = NSMAP)
    for md in range (len(Metadata)):
        mdentry = Metadata[md]
        Entity_val = mdentry.xpath('./XIP:Entity/text()', namespaces = NSMAP)
        for MDEntity in Entity_val:
            # print(f"MDEntity_val {MDEntity}")
            list_XIP_Entity.append(MDEntity)

    short_path = Path(path).parents[1]
    
    for dict_BSFileName_key, dict_BSFileName_val in dict_BSFileName.items():
        # print(f"dict_BSFileName_key {dict_BSFileName_key}")
        CORef_from_dict = dict_XIP_GenBitstream.get(dict_BSFileName_key, "NA")
        
        #         path             IORef      IO Title     IO Parent     CO Ref           CO Title                                     CO Parent                                     Full file path            File Name                                       File Size                                       
        listCO = [str(short_path), XIP_IORef, XIP_IOTitle, XIP_IOParent, CORef_from_dict, dict_XIP_COTitle.get(CORef_from_dict, "NA"), dict_XIP_COParent.get(CORef_from_dict, "NA"), str(dict_BSFileName_key), dict_BSFileName.get(dict_BSFileName_key, "NA"), dict_BSFileSize.get(dict_BSFileName_key, "NA"), "SHA1", dict_BSFileName_SHA1.get(dict_BSFileName_key, "NA"), "MD5", dict_BSFileName_MD5.get(dict_BSFileName_key, "NA")]
        dictCO[dict_BSFileName_key] = "|".join(listCO)


def fCleanUp(working_folder: Path):
    # print("Cleaning up the working directory")
    
    for oldfoldersfiles in working_folder.iterdir():
        # print(oldfoldersfiles)
        oldfoldersfiles_path = working_folder / oldfoldersfiles
        if oldfoldersfiles_path.is_dir():
            try:
                shutil.rmtree(oldfoldersfiles_path)
            except:
                logging.error(f" : fCleanUp : delete failed for folder {oldfoldersfiles}")
    
        elif oldfoldersfiles_path.is_file():
            try:
                oldfoldersfiles_path.unlink()
            except:
                logging.error(f" : fCleanUp : delete failed for file {oldfoldersfiles}")
                

def fGet_nsmap(tree):
    global NSMAP


def fConvertCSVtoXLSX(csvfilepath: Path, xlsxfilepath: Path):
    sub_r = "fConvertCSVtoXLSX"
        # logging.info(str(sub_r) + " : " + str(csvfilepath) + " submitted for conversion")
    logging.info(f"{sub_r} : {csvfilepath} submitted for conversion")
        # csvfile = os.path.basename(csvfilepath)
        # xlsxfile = os.path.basename(xlsxfilepath)
    # csvfile = csvfilepath.name()
    # xlsxfile = xlsxfilepath.name()
    workbook = Workbook(xlsxfilepath)
    worksheet = workbook.add_worksheet()
    with open(csvfilepath, 'rt', encoding='utf8') as f:
        reader = csv.reader(f, delimiter='|')
        for r, row in enumerate(reader):
            for c, col in enumerate(row):
                worksheet.write(r, c, col)
    workbook.close()


def fReset_Lists_Dicts():
    list_unpacked_export_zips.clear()
    list_XIP_IORef.clear()
    list_XIP_IOTitle.clear()
    list_XIP_IOParent.clear()
    list_XIP_Entity.clear()
    list_XIP_WorkingPath.clear()

    dict_XIP_IORef.clear()
    dict_XIP_IOTitle.clear()
    dict_XIP_IOParent.clear()
    dict_XIP_CORef.clear()
    dict_XIP_COTitle.clear()
    dict_XIP_COParent.clear()
    dict_XIP_GenRef.clear()
    dict_XIP_GenBitstream.clear()
    dict_BSFileName.clear()
    dict_BSFileSize.clear()
    dict_BSFileName_MD5.clear()
    dict_BSFileName_SHA1.clear()
    dict_BSFileName_SHA256.clear()
    dict_BSFileName_SHA512.clear()
    dict_BSRepresentationType.clear()


###############################################################
#runtime
###############################################################
def main():

    return fProcessPackages(source_folder,working_folder, target_folder)

if __name__ == '__main__':
    main()



